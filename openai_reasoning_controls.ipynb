{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc87b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "# Ensure your API key is set in your environment\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"Client initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b065ad11",
   "metadata": {},
   "source": [
    "## The Test Problem\n",
    "\n",
    "We'll use a classic \"back-of-the-envelope\" estimation puzzle:\n",
    "\n",
    "> **\"How many piano tuners are there in Chicago?\"**\n",
    "\n",
    "This type of question has no obvious answer you can just look up. It requires breaking the problem into smaller, logical steps—exactly the kind of task where deeper reasoning should help. It's also a great way to see how different reasoning levels affect the quality and detail of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c93f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A slightly complex reasoning task\n",
    "prompt = \"Estimate the number of piano tuners in Chicago based on first principles. Use Fermi estimation steps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87ff97",
   "metadata": {},
   "source": [
    "## 1. Deliberation Control: `reasoning.effort`\n",
    "**Goal:** Control how much \"thinking\" the model does before answering.\n",
    "\n",
    "**Parameters:** `reasoning={\"effort\": \"low\" | \"medium\" | \"high\"}`\n",
    "\n",
    "We will compare \"low\" effort vs \"high\" effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b5b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function defined.\n"
     ]
    }
   ],
   "source": [
    "# Helper function to print results clearly\n",
    "def print_output(title, response):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Reasoning Tokens Used: {response.usage.output_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"Total Output Tokens: {response.usage.output_tokens}\")\n",
    "    print(f\"\\nFull Answer:\")\n",
    "    print(\"-\"*60)\n",
    "    print(response.output_text)\n",
    "    print(\"-\"*60)\n",
    "\n",
    "print(\"Helper function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f55103",
   "metadata": {},
   "source": [
    "### 1A. Low Reasoning Effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "068513a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Low Effort...\n",
      "\n",
      "============================================================\n",
      "  Low Effort Result\n",
      "============================================================\n",
      "Reasoning Tokens Used: 0\n",
      "Total Output Tokens: 627\n",
      "\n",
      "Full Answer:\n",
      "------------------------------------------------------------\n",
      "### Goal  \n",
      "Estimate the number of **piano tuners in Chicago** using a **Fermi (first-principles) approach**.\n",
      "\n",
      "---\n",
      "\n",
      "## 1) Population of Chicago\n",
      "Use city proper (not metro), since the question says “in Chicago.”\n",
      "\n",
      "- Chicago population ≈ **2.7 million** people\n",
      "\n",
      "Assume average household size:\n",
      "\n",
      "- ≈ **2.5 people/household**  \n",
      "- Households ≈ 2.7M / 2.5 ≈ **1.1 million households**\n",
      "\n",
      "---\n",
      "\n",
      "## 2) How many pianos are there?\n",
      "We estimate the fraction of households with a piano.\n",
      "\n",
      "- Many homes don’t have one; some schools/churches/venues do.\n",
      "- Assume **~5% of households** have a piano (upright or grand).  \n",
      "  - Pianos in households ≈ 1.1M × 0.05 ≈ **55,000**\n",
      "\n",
      "Now add **institutions** (schools, churches, universities, venues, studios).\n",
      "\n",
      "A rough institutional estimate:\n",
      "- Suppose there are on the order of **a few thousand** institutions that might own pianos, with **1–3 pianos each** on average.\n",
      "- Ballpark **10,000–20,000** institutional pianos.\n",
      "\n",
      "So total pianos in Chicago:\n",
      "- **≈ 55,000 + 15,000 ≈ 70,000 pianos**\n",
      "\n",
      "(We only need order-of-magnitude accuracy.)\n",
      "\n",
      "---\n",
      "\n",
      "## 3) How often does a piano get tuned per year?\n",
      "Standard guidance is 1–2 tunings/year, but many owners tune less often.\n",
      "\n",
      "Assume average across all pianos (including neglected ones):\n",
      "\n",
      "- **0.8 tunings per piano per year** (some do 0, some do 1–2+)\n",
      "\n",
      "Annual tuning jobs:\n",
      "- 70,000 pianos × 0.8 ≈ **56,000 tunings/year**\n",
      "\n",
      "---\n",
      "\n",
      "## 4) How many tunings can one tuner do per year?\n",
      "Estimate tuner productivity:\n",
      "\n",
      "- Tunings/day: **~2** (travel + time on site; could be 1–3)\n",
      "- Workdays/year: **~240** (5 days/week × ~48 weeks)\n",
      "\n",
      "Tunings per tuner per year:\n",
      "- 2 × 240 = **480 tunings/year**\n",
      "\n",
      "---\n",
      "\n",
      "## 5) Estimate number of tuners\n",
      "Number of tuners ≈ total annual tunings / tunings per tuner/year\n",
      "\n",
      "- 56,000 / 480 ≈ **117 tuners**\n",
      "\n",
      "Round to a sensible Fermi estimate:\n",
      "\n",
      "### **Estimated piano tuners in Chicago: ~100 (order of magnitude: 50–200)**\n",
      "\n",
      "---\n",
      "\n",
      "## Quick sanity check (optional intuition)\n",
      "A city of a few million having on the order of **~100 specialized tradespeople** serving a niche durable-good market (like piano tuning) is plausible.\n",
      "\n",
      "---\n",
      "\n",
      "**Final estimate:** **~100 piano tuners in Chicago** (likely range **~50–200** depending on piano ownership and tuning frequency).\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1A. Low Effort\n",
    "print(\"Requesting Low Effort...\")\n",
    "response_low = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    reasoning={\"effort\": \"low\"}\n",
    ")\n",
    "print_output(\"Low Effort Result\", response_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4eb2b",
   "metadata": {},
   "source": [
    "### 1B. High Reasoning Effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe832da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting High Effort...\n",
      "\n",
      "============================================================\n",
      "  High Effort Result\n",
      "============================================================\n",
      "Reasoning Tokens Used: 484\n",
      "Total Output Tokens: 1145\n",
      "\n",
      "Full Answer:\n",
      "------------------------------------------------------------\n",
      "### Goal\n",
      "Estimate the number of **full‑time equivalent (FTE) piano tuners serving Chicago** using a Fermi approach.\n",
      "\n",
      "I’ll interpret “Chicago” as **city proper** (not the whole metro). The result will be order‑of‑magnitude.\n",
      "\n",
      "---\n",
      "\n",
      "## 1) How many pianos are in Chicago?\n",
      "\n",
      "**Population / households**\n",
      "- Chicago population ≈ **2.7 million**\n",
      "- Average household size ≈ **2.4**\n",
      "- Households ≈ 2.7M / 2.4 ≈ **1.1 million households**\n",
      "\n",
      "**Fraction of households with a piano**\n",
      "- Many households don’t; some do (kids’ lessons, hobbyists, inherited uprights).\n",
      "- Assume **~3%** of households have a piano (ballpark 1–5%).\n",
      "- Household pianos ≈ 1.1M × 0.03 ≈ **33,000 pianos**\n",
      "\n",
      "**Non-household pianos (institutions/businesses)**\n",
      "Schools, churches, universities, rehearsal studios, venues, hotels, etc.\n",
      "- As a rough add-on, assume institutions contribute **~25%** of the household count.\n",
      "- Institutional pianos ≈ 0.25 × 33,000 ≈ **8,000 pianos**\n",
      "\n",
      "**Total pianos**\n",
      "- Total ≈ 33,000 + 8,000 ≈ **41,000 pianos**\n",
      "\n",
      "---\n",
      "\n",
      "## 2) How many tunings per year does that imply?\n",
      "\n",
      "Not every piano is tuned annually; some are neglected, while performance instruments may be tuned multiple times/year.\n",
      "\n",
      "Assume an **average of 0.6 tunings per piano per year** (i.e., some at 1/yr, many at ~0).\n",
      "- Annual tuning jobs ≈ 41,000 × 0.6 ≈ **25,000 tunings/year**\n",
      "\n",
      "---\n",
      "\n",
      "## 3) How many tunings can one tuner do per year?\n",
      "\n",
      "Typical on-site tuning time plus travel/admin suggests around **2 tunings/day** is plausible on average (sometimes 1, sometimes 3).\n",
      "\n",
      "Assume:\n",
      "- 2 tunings/day\n",
      "- 5 days/week\n",
      "- 48 working weeks/year (allowing for vacation/slow periods)\n",
      "\n",
      "Tunings per tuner-year:\n",
      "- 2 × 5 × 48 ≈ **480 tunings/tuner/year**\n",
      "\n",
      "---\n",
      "\n",
      "## 4) Tuners needed\n",
      "\n",
      "\\[\n",
      "\\text{Tuners} \\approx \\frac{25{,}000}{480} \\approx 52\n",
      "\\]\n",
      "\n",
      "### Estimate: **~50 piano tuners (FTE) in Chicago**\n",
      "\n",
      "---\n",
      "\n",
      "## Sensitivity / range (to show robustness)\n",
      "If assumptions shift:\n",
      "- Piano ownership 2–5% and tuning rate 0.4–0.8/year and productivity 400–600/year\n",
      "\n",
      "You’d get a range roughly:\n",
      "- **~30 to ~90 tuners**, with **~50** as the central estimate.\n",
      "\n",
      "---\n",
      "\n",
      "If you want, I can redo the same estimate for the **Chicago metro area** (which will come out several times larger) or cross-check using alternative drivers (music students, schools/church counts, etc.).\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1B. High Effort\n",
    "print(\"Requesting High Effort...\")\n",
    "response_high = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    reasoning={\"effort\": \"high\"}\n",
    ")\n",
    "print_output(\"High Effort Result\", response_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf3406",
   "metadata": {},
   "source": [
    "## 2. Stopping Controls: `max_output_tokens`\n",
    "**Goal:** Prevent runaway costs or \"overthinking\" by setting a hard budget on total output tokens.\n",
    "\n",
    "**Parameter:** `max_output_tokens=500` \n",
    "\n",
    "This caps the *total* output token budget (reasoning + visible answer). When paired with high effort, if the model spends too many tokens reasoning, the visible answer may be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65640f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting High Effort with Output Budget (500 tokens)...\n",
      "\n",
      "============================================================\n",
      "  Budget Constrained Result\n",
      "============================================================\n",
      "Reasoning Tokens Used: 500\n",
      "Total Output Tokens: 500\n",
      "\n",
      "Full Answer:\n",
      "------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[INFO] Budget: 500 tokens\n",
      "  - Reasoning tokens: 500\n",
      "  - Visible answer tokens: 0\n",
      "  - Total output: 500\n",
      "[!] Output may have been truncated due to budget constraint.\n"
     ]
    }
   ],
   "source": [
    "# 2. Strict Output Budget\n",
    "# We set a total output token limit (reasoning + visible answer)\n",
    "output_budget = 500\n",
    "\n",
    "print(f\"Requesting High Effort with Output Budget ({output_budget} tokens)...\")\n",
    "\n",
    "response_budget = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    reasoning={\"effort\": \"high\"},\n",
    "    max_output_tokens=output_budget\n",
    ")\n",
    "\n",
    "print_output(\"Budget Constrained Result\", response_budget)\n",
    "\n",
    "# Check token usage\n",
    "reasoning_used = response_budget.usage.output_tokens_details.reasoning_tokens\n",
    "total_output = response_budget.usage.output_tokens\n",
    "visible_tokens = total_output - reasoning_used\n",
    "\n",
    "print(f\"\\n[INFO] Budget: {output_budget} tokens\")\n",
    "print(f\"  - Reasoning tokens: {reasoning_used}\")\n",
    "print(f\"  - Visible answer tokens: {visible_tokens}\")\n",
    "print(f\"  - Total output: {total_output}\")\n",
    "\n",
    "if total_output >= output_budget:\n",
    "    print(\"[!] Output may have been truncated due to budget constraint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7c498",
   "metadata": {},
   "source": [
    "## 3. Output Shaping via Prompt Engineering\n",
    "**Goal:** Control what the user actually sees, regardless of the internal reasoning depth.\n",
    "\n",
    "**Technique:** Since the Responses API doesn't support `response_format`, we use explicit prompt instructions to shape the output into JSON.\n",
    "\n",
    "Even if the model thinks for thousands of tokens, we can ask it to deliver a clean JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9b4fb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting High Effort with Output Shaping (JSON via Prompt)...\n",
      "\n",
      "--- Shaped Output (High Reasoning, JSON View) ---\n",
      "Reasoning Tokens (Hidden): 1013\n",
      "Visible Answer:\n",
      "{\n",
      "  \"population_chicago\": 2700000,\n",
      "  \"households_with_pianos\": 0.05,\n",
      "  \"tuning_frequency_per_year\": 1.0,\n",
      "  \"total_tunings_needed\": 54000,\n",
      "  \"tunings_per_tuner_per_year\": 500,\n",
      "  \"estimated_tuners\": 108\n",
      "}\n",
      "\n",
      "[SUCCESS] Output is valid JSON.\n"
     ]
    }
   ],
   "source": [
    "# 3. Structured Output (via Prompt Engineering)\n",
    "# Since the 'response_format' parameter is not currently supported by the client.responses.create method \n",
    "# in this environment, we will use explicit prompt instructions to shape the output into JSON.\n",
    "\n",
    "json_instruction = \"\"\"\n",
    "Output the final answer as a valid JSON object with the following keys:\n",
    "- population_chicago (integer)\n",
    "- households_with_pianos (number, decimal % estimate)\n",
    "- tuning_frequency_per_year (number)\n",
    "- total_tunings_needed (integer)\n",
    "- tunings_per_tuner_per_year (integer)\n",
    "- estimated_tuners (integer)\n",
    "\n",
    "Do not include markdown formatting (like ```json). Just the raw JSON string.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nRequesting High Effort with Output Shaping (JSON via Prompt)...\")\n",
    "\n",
    "# Append instructions to the user prompt\n",
    "shaped_prompt = prompt + \"\\n\\n\" + json_instruction\n",
    "\n",
    "response_shaped = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=[{\"role\": \"user\", \"content\": shaped_prompt}],\n",
    "    reasoning={\"effort\": \"high\"}\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Shaped Output (High Reasoning, JSON View) ---\")\n",
    "print(f\"Reasoning Tokens (Hidden): {response_shaped.usage.output_tokens_details.reasoning_tokens}\")\n",
    "print(f\"Visible Answer:\\n{response_shaped.output_text}\")\n",
    "\n",
    "# Verify it parses as JSON\n",
    "try:\n",
    "    data = json.loads(response_shaped.output_text)\n",
    "    print(\"\\n[SUCCESS] Output is valid JSON.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\n[WARNING] Output is not valid JSON (Prompt shaping is less strict than response_format).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning-models-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
